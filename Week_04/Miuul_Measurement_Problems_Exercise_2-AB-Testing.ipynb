{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# AB Testi ile Bidding Yöntemlerinin Dönüşümünün Karşılaştırılması\n",
        "\n",
        "**İş Problemi**\n",
        "\n",
        "Facebook kısa süre önce mevcut \"maximumbidding\" adı verilen teklif verme türüne alternatif\n",
        "olarak yeni bir teklif türü olan \"average bidding\"’i tanıttı. Müşterilerimizden biri olan bombabomba.com,\n",
        "bu yeni özelliği test etmeye karar verdi veaveragebidding'in maximumbidding'den daha fazla dönüşüm\n",
        "getirip getirmediğini anlamak için bir A/B testi yapmak istiyor.A/B testi 1 aydır devam ediyor ve\n",
        "bombabomba.com şimdi sizden bu A/B testinin sonuçlarını analiz etmenizi bekliyor. Bombabomba.com için\n",
        "nihai başarı ölçütü Purchase'dır. Bu nedenle, istatistiksel testler için Purchase metriğine odaklanılmalıdır.\n",
        "\n",
        "*Veri Seti Hikayesi*\n",
        "\n",
        "Bir firmanın web site bilgilerini içeren bu veri setinde kullanıcıların gördükleri ve tıkladıkları\n",
        "reklam sayıları gibi bilgilerin yanı sıra buradan gelen kazanç bilgileri yer almaktadır.Kontrol ve Test\n",
        "grubu olmak üzere iki ayrı veri seti vardır. Bu veri setleriab_testing.xlsxexcel’ininayrı sayfalarında yer\n",
        "almaktadır. Kontrol grubuna Maximum Bidding, test grubuna AverageBiddinguygulanmıştır.\n",
        "\n",
        "- impression: Reklam görüntüleme sayısı\n",
        "- Click: Görüntülenen reklama tıklama sayısı\n",
        "- Purchase: Tıklanan reklamlar sonrası satın alınan ürün sayısı\n",
        "- Earning: Satın alınan ürünler sonrası elde edilen kazanç\n",
        "\n",
        "\n",
        "**Proje Görevleri**\n",
        "\n",
        "> *AB Testing (Bağımsız İki Örneklem T Testi)*\n",
        "\n",
        "1.   Hipotezleri Kur\n",
        "2.   Varsayım Kontrolü\n",
        "  - Normallik Varsayımı (shapiro)\n",
        "  - Varyans Homojenliği (levene)\n",
        "3. Hipotezin Uygulanması\n",
        "  - Varsayımlar sağlanıyorsa bağımsız iki örneklem t testi\n",
        "  - Varsayımlar sağlanmıyorsa mannwhitneyu testi\n",
        "4. p-value değerine göre sonuçları yorumla\n",
        "\n",
        "Not:\n",
        "- Normallik sağlanmıyorsa direkt 2 numara. Varyans homojenliği sağlanmıyorsa 1 numaraya arguman girilir.\n",
        "- Normallik incelemesi öncesi aykırı değer incelemesi ve düzeltmesi yapmak faydalı olabilir."
      ],
      "metadata": {
        "id": "3mX7Q5Aj5m6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Görev 1:  Veriyi Hazırlama ve Analiz Etme**"
      ],
      "metadata": {
        "id": "x9wo-1vy7AX2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cra7kbJ5Am2"
      },
      "outputs": [],
      "source": [
        "# Adım 1:  ab_testing_data.xlsx adlı kontrol ve test grubu verilerinden oluşan veri setini okutunuz. Kontrol ve test grubu verilerini ayrı değişkenlere atayınız.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import shapiro, levene, ttest_ind\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
        "\n",
        "control_df = pd.read_excel(\"src/measurement_problems/ABTesti/ab_testing.xlsx\", sheet_name=\"Control Group\")\n",
        "test_df = pd.read_excel(\"src/measurement_problems/ABTesti/ab_testing.xlsx\", sheet_name=\"Test Group\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adım 2: Kontrol ve test grubu verilerini analiz ediniz.\n",
        "def missing_values_analysis(data):\n",
        "    na_columns = [col for col in data.columns if data[col].isnull().sum() > 0]\n",
        "    n_miss = data[na_columns].isnull().sum().sort_values(ascending=True)\n",
        "    ratio = (data[na_columns].isnull().sum() / data.shape[0] * 100).sort_values(ascending=True)\n",
        "    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['Total Missing Values', 'Ratio'])\n",
        "    missing_df = pd.DataFrame(missing_df)\n",
        "    return missing_df\n",
        "\n",
        "def check_dataframe(data, row_num=5):\n",
        "    print(\"*************** Dataset Shape ***************\")\n",
        "    print(\"No. of Rows:\", data.shape[0], \"\\nNo. of Columns:\", data.shape[1])\n",
        "    print(\"*************** Dataset Information ***************\")\n",
        "    print(data.info())\n",
        "    print(\"*************** Types of Columns ***************\")\n",
        "    print(data.dtypes)\n",
        "    print(f\"*************** First {row_num} Rows ***************\")\n",
        "    print(data.head(row_num))\n",
        "    print(f\"*************** Last {row_num} Rows ***************\")\n",
        "    print(data.tail(row_num))\n",
        "    print(\"*************** Summary Statistics of The Dataset ***************\")\n",
        "    print(data.describe().T)\n",
        "    print(\"*************** Dataset Missing Values Analysis ***************\")\n",
        "    print(missing_values_analysis(data))\n",
        "\n",
        "\n",
        "\n",
        "check_dataframe(control_df)\n",
        "check_dataframe(test_df)\n"
      ],
      "metadata": {
        "id": "ufHbMA7A6xpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adım 3: Analiz işleminden sonra concat metodunu kullanarak kontrol ve test grubu verilerini birleştiriniz.\n",
        "test_df['group'] = 'test'\n",
        "control_df['group'] = 'control'\n",
        "df = pd.concat([control_df, test_df], axis=0, ignore_index=True)\n",
        "\n",
        "df.head(5)\n",
        "df.tail(5)\n"
      ],
      "metadata": {
        "id": "rUuCTU_Z61vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Görev 2:  A/B Testinin Hipotezinin Tanımlanması**\n"
      ],
      "metadata": {
        "id": "NB4iAoq_7K5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adım 1: Hipotezi tanımlayınız.\n",
        "############################\n",
        "# 1. Hipotezi Kur\n",
        "############################\n",
        "\n",
        "# H0: M1 = M2 satın alınan ürün sayısı arasında istatistiksel olarak anlamlı bir fark yoktur\n",
        "# H1: M1 != M2 fark vardır\n",
        "\n",
        "# Adım 2: Kontrol ve test grubu için purchase(kazanç) ortalamalarını analiz ediniz\n",
        "df.groupby(\"group\").agg({'Purchase':'mean'})\n"
      ],
      "metadata": {
        "id": "atxijw307LC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GÖREV 3: Hipotez Testinin Gerçekleştirilmesi**\n"
      ],
      "metadata": {
        "id": "TzFHXxgU8Ps2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################\n",
        "# AB Testing (Bağımsız İki Örneklem T Testi)\n",
        "######################################################\n",
        "\n",
        "\n",
        "# Adım 1: Hipotez testi yapılmadan önce varsayım kontrollerini yapınız.Bunlar Normallik Varsayımı ve Varyans Homojenliğidir.\n",
        "\n",
        "# Kontrol ve test grubunun normallik varsayımına uyup uymadığını Purchase değişkeni üzerinden ayrı ayrı test ediniz\n",
        "\n",
        "############################\n",
        "# Normallik Varsayımı\n",
        "############################\n",
        "\n",
        "# H0: Normal dağılım varsayımı sağlanmaktadır.\n",
        "# H1:..sağlanmamaktadır.\n",
        "# p-value < 0.05'ten HO RED.\n",
        "# p-value > 0.05 H0 REDDEDILEMEZ.\n",
        "\n",
        "test_stat, pvalue = shapiro(df.loc[df[\"group\"] == \"control\", \"Purchase\"])\n",
        "print('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))\n",
        "#Test Stat = 0.9773, p-value = 0.5891\n",
        "\n",
        "test_stat, pvalue = shapiro(df.loc[df[\"group\"] == \"test\", \"Purchase\"])\n",
        "print('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))\n",
        "#Test Stat = 0.9589, p-value = 0.1541\n",
        "\n",
        "#her iki grubun p-value 0.05'ten büyük olduğu içi H0 reddedilemez\n",
        "\n",
        "############################\n",
        "# Varyans Homojenligi Varsayımı\n",
        "############################\n",
        "\n",
        "# H0: Varyanslar Homojendir\n",
        "# H1: Varyanslar Homojen Değildir\n",
        "\n",
        "test_stat, pvalue = levene(df.loc[df[\"group\"] == \"control\", \"Purchase\"],\n",
        "                           df.loc[df[\"group\"] == \"test\", \"Purchase\"])\n",
        "print('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))\n",
        "#Test Stat = 2.6393, p-value = 0.1083\n",
        "# p-value < 0.05 'ten HO RED.\n",
        "# p-value > 0.05 H0 REDDEDILEMEZ.\n",
        "\n",
        "#p-value değeri 0.05'ten büyük olduğu için H0 reddedilemez\n"
      ],
      "metadata": {
        "id": "iDRpkBG-8P2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adım 2: Normallik Varsayımı ve Varyans Homojenliği sonuçlarına göre uygun testi seçiniz\n",
        "# Varsayımlar sağlandığı için bağımsız iki örneklem t testi (parametrik test)\n",
        "test_stat, pvalue = ttest_ind(df.loc[df[\"group\"] == \"control\", \"Purchase\"],\n",
        "                              df.loc[df[\"group\"] == \"test\", \"Purchase\"],\n",
        "                              equal_var=True)\n",
        "\n",
        "print('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))\n",
        "# Test Stat = -0.9416, p-value = 0.3493\n",
        "# p-value < ise 0.05 'ten HO RED.\n",
        "# p-value < değilse 0.05 H0 REDDEDILEMEZ.\n"
      ],
      "metadata": {
        "id": "iWuzz9Bj8ZRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adım 3: Test sonucunda elde edilen p_value değerini göz önünde bulundurarak kontrol ve test grubu satın alma\n",
        "# ortalamaları arasında istatistiki olarak anlamlı bir fark olup olmadığını yorumlayınız.\n",
        "\n",
        "#p-value değeri 0.05'ten büyük olduğu için H0 reddedilemez\n",
        "# satın alınan ürün sayısında istatistiksel olarak anlamlı bir farkın olmadığı gözlemlenebilmektedir\n"
      ],
      "metadata": {
        "id": "OyeMjJBm8hOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GÖREV 4 : Sonuçların Analizi**"
      ],
      "metadata": {
        "id": "bPzCL6UO8kcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adım 1: Hangi testi kullandınız, sebeplerini belirtiniz.\n",
        "# Kontrol ve test grubunun normallik varsayımına uyup uymadığını test etmek için Shapiro testi uyguladık\n",
        "# normallik varsayımı sağlandığı için varyans homojenliğini kontrol ettik\n",
        "# İki grubun varyans homojenliği gözlemleyebilmek için Levene testi kullandık.\n",
        "# test sonucu varyans homojenlikleri arasında benzerlik olduğu gördük\n",
        "# iki grup arasındaki istatistiksel anlamları ortaya çıkarabilmek için Bağımsız İki Örneklem T Testi uyguladık\n",
        "\n",
        "\n",
        "# Adım 2: Elde ettiğiniz test sonuçlarına göre müşteriye tavsiyede bulununuz.\n",
        "# Test ve kontrol grupları arasında ortalama açısından anlamlı bir fark olmadığı tespit edildiği için\n",
        "# average bidding ve maximum bidding teklif yöntemlerinin her ikisini de kullanabilir\n"
      ],
      "metadata": {
        "id": "X8pbjavT8kkF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
